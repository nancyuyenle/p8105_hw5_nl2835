---
title: "p8105_hw5_nl2835"
author: "Nancy Le"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
library(purrr)

```


```{r load csv file}
homicides <-
  read.csv("./local/homicide-data.csv") |> 
  janitor::clean_names() |> 
  separate(reported_date, into = c("year", "month", "day"), sep = c(4,6))  
```

## Problem 1

The raw data describes victim name, race, age, sex, location of homicide, and whether an arrest was made.

```{r}
homicides = homicides |> 
  mutate(city_state = paste(city, state, sep = ", ")) |> 
  group_by(city_state) 

```

```{r count number of homicides}
homicides |> 
  summarize(count = n())
```

There are `r nrow(homicides)` homicides from 2010 to 2016.

```{r}
homicides |> 
  filter(disposition == "Closed without arrest" | disposition == "Open/No arrest") |> 
  summarize(count = n())
```

There are `r nrow(homicides |> filter(disposition == "Closed without arrest" | disposition == "Open/No arrest"))` unsolved homicides. 


```{r df unsolved}
baltimore = homicides |> 
  filter(city_state == "Baltimore, MD") |> 
  mutate(
    unresolved = as.numeric(disposition == "Closed without arrest" | disposition == "Open/No arrest")) |> 
  select(city_state, unresolved, everything()) |> 
  group_by(unresolved) |> 
  summarize(number = n()) |> 
  mutate(total = sum(number)) |> 
  filter(unresolved == 1) |> 
  select(number, total)
```

```{r prop test}
baltimore_pt = 
  prop.test(baltimore$number, baltimore$total) |>
  broom::tidy() |> 
  janitor::clean_names()

baltimore_pt |> 
  select(estimate, conf_low, conf_high) |> knitr::kable()
```

The estimated proportion of homicides unsolved is 0.6456 with a confidence interval of [0.627, 0.663].

**do rest of prop tests for each city later

## Problem 2

```{r tidy df with all participants}
names = list.files(path="./local/data", full.names=TRUE)

readin_csv = function(path) {
  df =
    read_csv(path) |>
    janitor::clean_names() |>
    mutate(
      id = path
    ) |> 
    mutate(arm = substr(id, 14, 16), id = substr(id, 18, 19))
} |> 
  select(everything())

output = map(names, readin_csv) |> bind_rows()

```

```{r tidy further}
output = output |> 
  pivot_longer(week_1:week_8,
               names_to = "week", 
               values_to = "value") |> 
  mutate(week = substr(week, 6, 7))
```

```{r spaghetti plot}
output |> 
  mutate(week = as.numeric(week)) |> 
  ggplot(aes(x = week, y = value, color = id)) + geom_line() + facet_grid(~arm)
```

The experimental arm had higher average values overall and an increase over time, compared to the control arm that had lower average values and a decrease over time. 

## Problem 3

```{r}
set.seed(1)

sim_ttest = function(mu) {
  data = tibble(
    x = rnorm(n=30, mean=mu, sd = 5)
  )
  
output = data |> 
  t.test() |> 
  broom::tidy() |> 
  select(estimate, p.value) |> 
  rename(p_value = p.value)
}

sim_results_df = 
  expand_grid(
    mu = c(0, 1, 2, 3, 4, 5, 6),
    iter = 1:50) |> 
  mutate(
    estimate_df = map(mu, sim_ttest) ) |> 
  unnest(estimate_df)
```

```{r plot of proportion times null rejected and true value}
sim_results_df |> 
  group_by(mu) |> 
  summarize(
    power = sum(p_value < 0.05),
    power_prop = power/50
  ) |> 
  ggplot(aes(x = mu, y= power_prop)) + geom_line()

```

The association between effect size and power is positive. 

```{r avg est mu vs true mu}
mu_avg = sim_results_df |> 
  group_by(mu) |> 
  summarize(
  mu_avg = mean(estimate))

null_rej = sim_results_df |> 
  filter(p_value <0.05) |> 
  group_by(mu) |> 
  summarize(
    mu_avg = mean(estimate)
  )

ggplot(mu_avg, aes(x = mu, y = mu_avg)) +
  geom_line() +
  geom_line(data = null_rej, color = "blue")
```


There is almost an exactly linear relationship between the true value of mu and the average estimate of mu in all samples. 

In samples where the null was rejected, the sample average of mu across tests is not approximately equal to the true value of mu for lower effect sizes, because a lower effect size indicates weaker power and a lower probability that H0 is false.



